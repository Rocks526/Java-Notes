# 一：数据结构基本概念

### 1.1 什么是数据结构

`数据`是信息的载体，是描述客观事物属性的数、字符以及所有能输入计算机中并被程序识别和处理的`符号的集合`。

`数据对象`是具有相同性质的数据元素的集合，即数据的一个子集。

`数据元素`是数据的基本单位，通常作为一个整体进行考虑和处理。

`数据项`是构成数据元素的不可分割最小单位。

`数据结构`是相互之间存在一种或多种特定关系的数据元素的集合。

数据结构三要素：

- 逻辑结构：逻辑上的结构，与现实世界映射，便于我们解决一些特定场景的问题
- 物理结构：数据在物理上的存储结构，一种逻辑结构往往有多种物理结构的实现
- 数据的运算：对集合中元素的一系列操作

### 1.2 常见的逻辑结构

数据的逻辑结构与现实世界映射，之所以抽象出逻辑结构是为了解决现实世界中的问题。常见的逻辑接口有以下几种：

- 线性结构

元素之间只有一对一的线性关系，例如现实世界中的排队场景。

> 除了线性结构外，以下几种都属于非线性结构。

- 集合

元素彼此之前没有明显的关系，只是一组同样元素的集合，例如现实世界中水果店卖的多种水果。

- 树形结构

元素之间存在一对多的关系，存在上下明显的层级结构，例如现实世界中的组织架构等。

- 图形结构

元素之间存在任意一对多、多对多关系，多个元素彼此交叉形成网状结构，例如现实世界的社交关系网。

### 1.3 常见的物理结构

数据的物理结构是其在计算机之上的实际存储方式，各种逻辑结构都有多种物理存储结构的实现，常见的有以下几种：

- 顺序存储

在内存或磁盘上开辟出连续的空间，所有元素依次排列顺序存储。

`优点是只要知道起点和元素的下标，即可快速计算出对应元素存储的位置。`

`缺点是往指定下标新增元素或删除元素时，为了保证顺序结构，后续的元素都得移动，开销很大，并且存储内存必须连续，每个元素占用大小一样，综合占用空间较大。`

- 链式存储

在内存或磁盘上链式存储，每个元素除了存储自己本身的信息之外，还存储下一个元素的地址，通过上一个元素可以找到下一个元素。

`优点是删除和新增元素时，只需要找到前一个元素，修改他们之间记录的下一个元素地址即可，并且允许内存不连续，当存在大量内存碎片时表现比顺序存储更好。`

`缺点是查询元素效率较低，只能从首节点往后遍历查找，并且由于每个元素除了存储本身的数据外，还需要存储下个元素的地址信息，对存储空间也有一定开销。`

- 索引存储

数据的存储方式可以顺序，也可以链式，也可以压缩存储，需要维护一张每个元素和地址映射的表。

`优点：当存在大量数据时，可以进行压缩存储，基于索引可以快速找到对应数据。`

`缺点：当数据存在变更时，索引也需要对应更新，且索引存储也会占用一部分空间。`

- 散列存储

元素基于某种散列函数计算得出存放的地址，散列函数保证每个元素多次计算得出的地址完全一致。

`优点：非常快速的查找性能。`

`缺点：不适合排序等，且存在散列冲突。`

### 1.4 数据的运算

数据的运算是针对集合中元素的一些操作，主要包括运算的定义和实现两部分，运算的定义是针对`逻辑结构`，运算的实现是针对`存储结构。`

# 二：算法和算法评价

### 2.1 算法的基本概念

#### 2.1.1 算法介绍

`算法`：对特定问题求解步骤的一种描述，它是指令的有限序列，其中每条指令表示一个或多个操作。

算法具备以下特点：

- 可行性
- 有穷性
- 确定性
- 有输入/输出

#### 2.1.2 算法和程序的区别

算法：算法是解决问题的一种方法或一个过程，考虑如何将输入转换成输出，一个问题可以有很多个算法。

程序：程序是某种程序设计语言对算法的具体实现。

- 算法必须是有穷的，程序可以是无穷的
- 算法必须是正确的，程序可以是错误的
- 算法可以用伪代码等描述，程序只能用代码编写并运行

### 2.2 算法的评价标准

#### 2.2.1 算法的优劣

将一个输入转换成输出，有多种算法可以实现，那么如何评价一个算法的好坏？

- 正确性：算法应该能正确求解问题
- 可读性：算法应该有良好的可读性，帮助人理解
- 健壮性：输入非法数据，算法能适应的做出反应和处理
- `效率和存储量`：效率是指算法执行时间，存储量是指算法执行过程中所需的存储空间

相比正确性、可读性、健壮性等算法必备的属性，效率和存储量更能区分一个算法的优劣。

算法的执行时间和占用的存储空间可以通过执行算法统计而得，但每次统计的结果可能都存在波动，并不是非常准确，且当数据量很大时，不能每次都先去执行一遍去统计，因此需要一种通用的公式来计算一个算法的效率和占用的存储空间，这个公式就是`时间复杂度`和`空间复杂度`。

#### 2.2.2 时间复杂度

时间复杂度和空间复杂度的计算方式有很多，最常用的是O(n)表示法：`T(n) = O(f(n))`。

其中，T(n) 表示代码执行的时间；n表示数据规模的大小；f(n) 表示每行代码执行的次数总和。

因为这是一个公式，所以用 f(n) 来表示。公式中的 O，表示代码的执行时间 T(n) 与 f(n) 表达式成正比。

> 大O时间复杂度实际上并不具体表示代码真正的执行时间，而是表示代码执行时间随数据规模增长的变化趋势，所以，也叫作渐进时间复杂度 （asymptotic time complexity），简称时间复杂度。
>
> 公式中的低阶、常量、系数三部分并不左右增长趋势，所以都可以忽略。我们只需要记录一个最大量级就可以了。

大O表示法有以下三个规则：

- 只关注循环执行次数最多的一段代码
- 加法法则：总复杂度等于量级最大的那段代码的复杂度
- 乘法法则：嵌套代码的复杂度等于嵌套内外代码复杂度的乘积

常见时间复杂度有：O(1)、O(logn)、O(nlogn)、O(m+n)、O(m*n)

<img src="http://rocks526.top/lzx/image-20210427172859860.png" alt="image-20210427172859860" style="zoom: 40%;" /><img src="http://rocks526.top/lzx/image-20210427173228884.png" alt="image-20210427173228884" style="zoom: 33%;" />

#### 2.2.3 空间复杂度

时间复杂度的全称是渐进时间复杂度，表示算法的执行时间与数据规模之间的增长关系。

类比一下，空间复杂度全称就是渐进空间复杂度（asymptotic space complexity），表示算法的存储空间与数据规模之间的增长关系。

常见的空间复杂度就是 O(1)、O(n)、O(n )。

### 2.3 最好 最坏 均摊

```java
// n 表示数组 array 的长度
int find(int[] array, int n, int x) {
 int i = 0;
 int pos = -1;
 for (; i < n; ++i) {
 if (array[i] == x) {
 pos = i;
 break;
 }
 }
 return pos;
}
```

最好情况时间复杂度：在最理想的情况下，执行这段代码的时间复杂度，上例为O(1)

最坏情况时间复杂度：在最糟糕的情况下，执行这段代码的时间复杂度，上例为O(n)

最好情况时间复杂度和最坏情况时间复杂度对应的都是极端情况下的代码复杂度，发生的概率其实并不大。为了更好地表示平均情况下的复杂度，需要引入另一个概念：平均情况时间复杂度，后面简称为`平均时间复杂度`。

平均时间复杂度的核心思路就是计算每种情况的概率和对应的时间复杂度进行加权计算，最终得出平均值。

除了以上三种之外，还有一种复杂度的计算方式：`均摊时间复杂度`。

均摊时间复杂度即将个别时间复杂度高的操作均摊到其他时间复杂度低的操作上，例如ArrayList的add方法，大部分时间复杂度O(1)，扩容时时间复杂度O(N)，平摊之后，时间复杂度为O(1)。



