# 并发编程存在的问题

![image-20210105184116718](http://rocks526.top/lzx/image-20210105184116718.png)

> http://assets.processon.com/chart_image/5ff4362bf346fb340de82755.png

并发编程中我们需要注意的问题有很多，很庆幸前人已经帮我们总结过了，分别是：**安全性问题、活跃性问题和性能问题**。

### 安全性问题

线程安全的其实本质上就是正确性，而正确性的含义就是**程序按照我们期望的执行**，不要让我们感到意外。

导致程序出现并发BUG的源头有三个：原子性问题、可见性问题和有序性问题。

> 这里隐含了一个潜在的前提，那就是对线程对共享变量进行操作才会存在并发问题。
>
> 如果变量不是共享的，是局部变量那么就不会导致并发问题。因此有一些别的保证线程安全的手段，例如线程私有，将共享变量消除。

在多线程对共享数据操作的过程中，可能存在两种并发错误：**数据竞争和静态条件**。

下面代码就会导致数据竞争，由于多线程都会访问count共享变量，有的线程就会读取旧的值导致计算错误。

```java
public class Test {
  private long count = 0;
  void add10K() {
    int idx = 0;
    while(idx++ < 10000) {
      count += 1;
    }
  }
}
```

下面代码通过给set和get方法加synchronizated锁解决数据竞争问题，但仍存不是线程安全的。这种叫**竞态条件**（Race Condition）。所谓**竞态条件，指的是程序的执行结果依赖线程执行的顺序**。简单理解就是单个操作是原子的，但set(get())的组合操作不是原子的。当程序出现if等逻辑时，需要重点注意竞态条件问题。

```java
public class Test {
  private long count = 0;
  synchronized long get(){
    return count；
  }
  synchronized void set(long v){
    count = v;
  } 
  void add10K() {
    int idx = 0;
    while(idx++ < 10000) {
      set(get()+1)      
    }
  }
}
```

### 活跃性问题

所谓活跃性问题，指的是某个操作无法执行下去。我们常见的“死锁”就是一种典型的活跃性问题，当然**除了死锁外，还有两种情况，分别是“活锁”和“饥饿”**。

通过前面的学习你已经知道，发生“死锁”后线程会互相等待，而且会一直等待下去，在技术上的表现形式是线程永久地“阻塞”了。

但**有时线程虽然没有发生阻塞，但仍然会存在执行不下去的情况，这就是所谓的“活锁”**。可以类比现实世界里的例子，路人甲从左手边出门，路人乙从右手边进门，两人为了不相撞，互相谦让，路人甲让路走右手边，路人乙也让路走左手边，结果是两人又相撞了。这种情况，基本上谦让几次就解决了，因为人会交流。可是如果这种情况发生在编程世界了，就有可能会一直没完没了地“谦让”下去，成为没有发生阻塞但依然执行不下去的“活锁”。

解决“**活锁**”的方案很简单，谦让时，尝试等待一个随机的时间就可以了。

**所谓“饥饿”指的是线程因无法访问所需资源而无法执行下去的情况**。“不患寡，而患不均”，如果线程优先级“不均”，在 CPU 繁忙的情况下，优先级低的线程得到执行的机会很小，就可能发生线程“饥饿”；持有锁的线程，如果执行的时间过长，也可能导致“饥饿”问题。

解决“**饥饿**”问题的方案很简单，有三种方案：一是保证资源充足，二是公平地分配资源，三就是避免持有锁的线程长时间执行。这三个方案中，方案一和方案三的适用场景比较有限，因为很多场景下，资源的稀缺性是没办法解决的，持有锁的线程执行的时间也很难缩短。倒是方案二的适用场景相对来说更多一些。

那如何公平地分配资源呢？在并发编程里，主要是使用公平锁。所谓公平锁，是一种先来后到的方案，线程的等待是有顺序的，排在等待队列前面的线程会优先获得资源。

### 性能问题

之前说过，锁是一个万能方案，但如果锁的粒度太粗可能导致串行化的范围过大，这样就不能够发挥多线程的优势了，而我们之所以使用多线程搞并发程序，为的就是提升性能。

> 阿姆达尔（Amdahl）定律：代表了处理器并行运算之后效率提升的能力
>
> ![image-20210105175929951](http://rocks526.top/lzx/image-20210105175929951.png)
>
> 公式里的 n 可以理解为 CPU 的核数，p 可以理解为并行百分比，那（1-p）就是串行百分比了，也就是我们假设的 5%。我们再假设 CPU 的核数（也就是 n）无穷大，那加速比 S 的极限就是 20。也就是说，如果我们的串行率是 5%，那么我们无论采用什么技术，最高也就只能提高 20 倍的性能。

所以使用锁的时候一定要关注对性能的影响。 那怎么才能避免锁带来的性能问题呢？

这个问题很复杂，之前使用synchronizated的时候，粒度粗会导致性能问题，粒度细又可能出现死锁等问题，为了预防死锁又需要引入循环等待，最后又通过等待-通知机制优化循环等待。在Jdk1.5之后，**Java SDK 并发包里之所以有那么多东西，有很大一部分原因就是要提升在某个特定领域的性能**。

在程序设计上，为了性能考虑，最好采用以下方案：

- 既然使用锁会带来性能问题，那最好的方案自然就是使用无锁的算法和数据结构了。在这方面有很多相关的技术，例如线程本地存储 (Thread Local Storage, TLS)、写入时复制 (Copy-on-write)、乐观锁等；Java 并发包里面的原子类也是一种无锁的数据结构
- 减少锁持有的时间。互斥锁本质上是将并行的程序串行化，所以要增加并行度，一定要减少持有锁的时间。这个方案具体的实现技术也有很多，例如使用细粒度的锁，一个典型的例子就是 Java 并发包里的 ConcurrentHashMap，它使用了所谓分段锁的技术；还可以使用读写锁，也就是读是无锁的，只有写的时候才会互斥。

# 如何编写并发程序

1. 编写并发程序要从宏观角度入手，考虑安全性、活跃性和性能问题
2. 管程是一个解决并发的万能钥匙，也是Java支持的并发模型，理论上来讲任何并发程序都可以通过管程解决(synchronized和Lock等)
3. 虽然Jdk1.6对synchronized做过优化，但synchronized存在只有一个条件变量、无法主动释放资源等等缺点，因此推荐使用Jdk5推出的juc包的Lock实现管程解决问题
4. juc包提供了很多并发工具，适合解决一些特定场景的需求，当存在场景时，优先采用这些工具实现，这些精心实现的并发工具远比自己通过管程实现有效

